<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Trees · BetaML.jl Documentation</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">BetaML.jl Documentation</span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Index</a></li><li><a class="tocitem" href="Perceptron.html">Perceptron</a></li><li class="is-active"><a class="tocitem" href="Trees.html">Trees</a><ul class="internal"><li><a class="tocitem" href="#Module-Index-1"><span>Module Index</span></a></li><li><a class="tocitem" href="#Detailed-API-1"><span>Detailed API</span></a></li></ul></li><li><a class="tocitem" href="Nn.html">Nn</a></li><li><a class="tocitem" href="Clustering.html">Clustering</a></li><li><a class="tocitem" href="Utils.html">Utils</a></li><li><a class="tocitem" href="Notebooks.html">Notebooks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="Trees.html">Trees</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Trees.html">Trees</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/Trees.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="The-BetaML.Trees-Module-1"><a class="docs-heading-anchor" href="#The-BetaML.Trees-Module-1">The BetaML.Trees Module</a><a class="docs-heading-anchor-permalink" href="#The-BetaML.Trees-Module-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees" href="#BetaML.Trees"><code>BetaML.Trees</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia">BetaML.Trees module</code></pre><p>Implement the functionality required to build a Decision Tree or a whole Random Forest, predict data and assess its performances.</p><p>Both Decision Trees and Random Forests can be used for regression or classification problems, based on the type of the labels (numerical or not). You can override the automatic selection with the parameter <code>forceClassification=true</code>, typically if your labels are integer representing some categories rather than numbers.</p><p>Missing data on features are supported.</p><p>Based originally on the <a href="https://www.youtube.com/watch?v=LDRbO9a6XPU">Josh Gordon&#39;s code</a></p><p>The module provide the following functions. Use <code>?[type or function]</code> to access their full signature and detailed documentation:</p><p><strong>Model definition and training:</strong></p><ul><li><code>buildTree</code>: Build a single Decision Tree</li><li><code>buildForest</code>: Build a &quot;forest&quot; of Decision Trees</li></ul><p><strong>Model predictions and assessment:</strong></p><ul><li><code>predict</code>: Return the prediction given the feature matrix</li><li><code>Utils.accuracy(tree or forest)</code>: Categorical output accuracy</li><li><code>Utils.mearRelError(tree or forest,p)</code>: L-p norm based error</li></ul><p>Features are expected to be in the standard format (nRecords × nDimensions matrices) and the labels (either categorical or numerical) as a nRecords column vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L14-L40">source</a></section></article><h2 id="Module-Index-1"><a class="docs-heading-anchor" href="#Module-Index-1">Module Index</a><a class="docs-heading-anchor-permalink" href="#Module-Index-1" title="Permalink"></a></h2><ul><li><a href="Trees.html#BetaML.Trees.AbstractQuestion"><code>BetaML.Trees.AbstractQuestion</code></a></li><li><a href="Trees.html#BetaML.Trees.DecisionNode"><code>BetaML.Trees.DecisionNode</code></a></li><li><a href="Trees.html#BetaML.Trees.Leaf"><code>BetaML.Trees.Leaf</code></a></li><li><a href="Trees.html#BetaML.Trees.buildForest-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty"><code>BetaML.Trees.buildForest</code></a></li><li><a href="Trees.html#BetaML.Trees.buildTree-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty"><code>BetaML.Trees.buildTree</code></a></li><li><a href="Trees.html#BetaML.Trees.computeTreesWeights-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Array{Array{Int64,1},1},Any,Any}} where Ty"><code>BetaML.Trees.computeTreesWeights</code></a></li><li><a href="Trees.html#BetaML.Trees.findBestSplit-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}} where Ty"><code>BetaML.Trees.findBestSplit</code></a></li><li><a href="Trees.html#BetaML.Trees.infoGain-Tuple{Any,Any,Any}"><code>BetaML.Trees.infoGain</code></a></li><li><a href="Trees.html#BetaML.Trees.match-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx"><code>BetaML.Trees.match</code></a></li><li><a href="Trees.html#BetaML.Trees.partition-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx"><code>BetaML.Trees.partition</code></a></li><li><a href="Trees.html#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx"><code>BetaML.Trees.predict</code></a></li><li><a href="Trees.html#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>BetaML.Trees.predict</code></a></li><li><a href="Trees.html#BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>BetaML.Trees.predictSingle</code></a></li><li><a href="Trees.html#BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx"><code>BetaML.Trees.predictSingle</code></a></li></ul><h2 id="Detailed-API-1"><a class="docs-heading-anchor" href="#Detailed-API-1">Detailed API</a><a class="docs-heading-anchor-permalink" href="#Detailed-API-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Base.print" href="#Base.print"><code>Base.print</code></a> — <span class="docstring-category">Function</span></header><section><div><p>print(node)</p><p>Print a Decision Tree (textual)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L329-L334">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.buildForest-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty" href="#BetaML.Trees.buildForest-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty"><code>BetaML.Trees.buildForest</code></a> — <span class="docstring-category">Method</span></header><section><div><p>buildForest(x, y, nTrees; maxDepth, minGain, minRecords, maxFeatures, splittingCriterion, forceClassification)</p><p>Builds (define and train) a &quot;forest&quot; of Decision Trees.</p><p><strong>Parameters:</strong></p><p>See <a href="Trees.html#BetaML.Trees.buildTree-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty"><code>buildTree</code></a>. The function has all the parameters of <code>bildTree</code> (with the <code>maxFeatures</code> defaulting to <code>√D</code> instead of <code>D</code>) plus the following parameters:</p><ul><li><code>nTrees</code>: Number of trees in the forest [def: <code>30</code>]</li><li><code>β</code>: Parameter that regulate the weights of the scoring of each tree, to be (optionally) used in prediction (see later) [def: <code>0</code>, i.e. uniform weigths]</li><li><code>oob</code>: Wheter to report the out-of-bag error, an estimation of the generalization accuracy [def: <code>false</code>]</li></ul><p><strong>Output:</strong></p><p>The function returns a named touple with the following elements:</p><ul><li><code>forest</code>: the forest ityself (array of Trees)</li><li><code>weights</code>: the per-tree weight based on their accuracy [def: to array of ones if <code>β ≤ 0</code>]</li><li><code>oob</code>:   the estimate of the oob error [def: to <code>+Inf</code> if <code>oob</code> == <code>false</code>]</li></ul><p><strong>Notes :</strong></p><ul><li>Each individual decision tree is built using bootstrap over the data, i.e. &quot;sampling N records with replacement&quot; (hence, some records appear multiple times and some records do not appear in the specific tree training). The <code>maxFeature</code> injects further variability and reduces the correlation between the forest trees.</li><li>The predictions of the &quot;forest&quot; (using the function <code>predict()</code>) are then the aggregated predictions of the individual trees (from which the name &quot;bagging&quot;: <strong>b</strong>oostrap <strong>agg</strong>regat<strong>ing</strong>).</li><li>This function optionally reports a weight distribution of the performances of eanch individual trees, as measured using the records he has not being trained with. These weights can then be (optionally) used in the <code>predict</code> function. The parameter <code>β ≥ 0</code> regulate the distribution of these weights: larger is <code>β</code>, the greater the importance (hence the weights) attached to the best-performing trees compared to the low-performing ones. Using these weights can significantly improve the forest performances (especially using small forests), however the correct value of β depends on the problem under exam (and the chosen caratteristics of the random forest estimator) and should be cross-validated to avoid over-fitting.</li><li>Note that this function uses muiltiple threads if these are available. You can check the number of threads available with <code>Threads.nthreads()</code>. To set the number of threads in Julia either set the environmental variable <code>JULIA_NUM_THREADS</code> (before starting Julia) or start Julia with the command line option <code>--threads</code> (most integrated development editors for Julia already set the number of threads to 4).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L404-L427">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.buildTree-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty" href="#BetaML.Trees.buildTree-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}, Tuple{Any,Array{Ty,1},Any}} where Ty"><code>BetaML.Trees.buildTree</code></a> — <span class="docstring-category">Method</span></header><section><div><p>buildTree(x, y, depth; maxDepth, minGain, minRecords, maxFeatures, splittingCriterion, forceClassification)</p><p>Builds (define and train) a Decision Tree.</p><p>Given a dataset of features <code>x</code> and the corresponding dataset of labels <code>y</code>, recursivelly build a decision tree by finding at each node the best question to split the data untill either all the dataset is separated or a terminal condition is reached. The given tree is then returned.</p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: The dataset&#39;s features (N × D)</li><li><code>y</code>: The dataset&#39;s labels (N × 1)</li><li><code>depth</code>: The current tree&#39;s depth. Used when calling the function recursively [def: <code>1</code>]</li><li><code>maxDepth</code>: The maximum depth the tree is allowed to reach. When this is reached the node is forced to become a leaf [def: <code>N</code>, i.e. no limits]</li><li><code>minGain</code>: The minimum information gain to allow for a node&#39;s partition [def: <code>0</code>]</li><li><code>minRecords</code>:  The minimum number of records a node must holds to consider for a partition of it [def: <code>2</code>]</li><li><code>maxFeatures</code>: The maximum number of (random) features to consider at each partitioning [def: <code>D</code>, i.e. look at all features]</li><li><code>splittingCriterion</code>: Either <code>gini</code>, <code>entropy</code> or <code>variance</code> (see <a href="Trees.html#BetaML.Trees.infoGain-Tuple{Any,Any,Any}"><code>infoGain</code></a> ) [def: <code>gini</code> for categorical labels (classification task) and <code>variance</code> for numerical labels(regression task)]</li><li><code>forceClassification</code>: Weather to force a classification task even if the labels are numerical (typically when labels are integers encoding some feature rather than representing a real cardinal measure) [def: <code>false</code>]</li></ul><p><strong>Notes:</strong></p><p>Missing data (in the feature dataset) are supported.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L266-L289">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.computeTreesWeights-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Array{Array{Int64,1},1},Any,Any}} where Ty" href="#BetaML.Trees.computeTreesWeights-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Array{Array{Int64,1},1},Any,Any}} where Ty"><code>BetaML.Trees.computeTreesWeights</code></a> — <span class="docstring-category">Method</span></header><section><div><p>computeTreesWeights(forest,notSampledByTree,x,y;forceClassification,β)</p><p>Compute the weights of each tree (to use in the prediction of the forest) based on the error of the individual tree computed on the records on which it has not been trained.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L503-L508">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty" href="#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>BetaML.Trees.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predict(forest,x;weights)</p><p>Predict the labels of a feature dataset.</p><p>For each record of the dataset and each tree of the &quot;forest&quot;, recursivelly traverse the tree to find the prediction most opportune for the given record. If the labels the tree has been trained with are numeric, the prediction is also numeric (the mean of the different trees predictions, in turn the mean of the labels of the training records ended in that leaf node). If the labels were categorical, the prediction is a dictionary with the probabilities of each item and in such case the probabilities of the different trees are averaged to compose the forest predictions. This is a bit different than most other implementations where the mode instead is reported.</p><p>In the first case (numerical predictions) use <code>meanRelError(ŷ,y)</code> to assess the mean relative error, in the second case you can use <code>accuracy(ŷ,y)</code>.</p><p>Optionally a weighted mean of tree&#39;s prediction is used if the parameter <code>weights</code> is given.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L483-L496">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx" href="#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx"><code>BetaML.Trees.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predict(tree,x)</p><p>Predict the labels of a feature dataset.</p><p>For each record of the dataset, recursivelly traverse the tree to find the prediction most opportune for the given record. If the labels the tree has been trained with are numeric, the prediction is also numeric. If the labels were categorical, the prediction is a dictionary with the probabilities of each item.</p><p>In the first case (numerical predictions) use <code>meanRelError(ŷ,y)</code> to assess the mean relative error, in the second case you can use <code>accuracy(ŷ,y)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L388-L398">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty" href="#BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>BetaML.Trees.predictSingle</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predictSingle(forest,x;weights)</p><p>Predict the label of a single feature record. See <a href="Trees.html#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>predict</code></a>. Optionally a weighted mean of tree&#39;s prediction is used if the parameter <code>weights</code> is given.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L465-L471">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx" href="#BetaML.Trees.predictSingle-Union{Tuple{Ty}, Tuple{Tx}, Tuple{Union{BetaML.Trees.DecisionNode{Tx,Ty}, BetaML.Trees.Leaf{Ty}},Any}} where Ty where Tx"><code>BetaML.Trees.predictSingle</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predictSingle(tree,x)</p><p>Predict the label of a single feature record. See <a href="Trees.html#BetaML.Trees.predict-Union{Tuple{Ty}, Tuple{Array{Union{BetaML.Trees.AbstractDecisionNodeTy{Ty}, BetaML.Trees.Leaf{Ty}},1},Any}} where Ty"><code>predict</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L367-L372">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.AbstractQuestion" href="#BetaML.Trees.AbstractQuestion"><code>BetaML.Trees.AbstractQuestion</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Question</p><p>A question used to partition a dataset.</p><p>This struct just records a &#39;column number&#39; and a &#39;column value&#39; (e.g., Green).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L49-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.DecisionNode" href="#BetaML.Trees.DecisionNode"><code>BetaML.Trees.DecisionNode</code></a> — <span class="docstring-category">Type</span></header><section><div><p>DecisionNode(question,trueBranch,falseBranch, depth)</p><p>A tree&#39;s non-terminal node.</p><p><strong>Constructor&#39;s arguments and struct members:</strong></p><ul><li><code>question</code>: The question asked in this node</li><li><code>trueBranch</code>: A reference to the &quot;true&quot; branch of the trees</li><li><code>falseBranch</code>: A reference to the &quot;false&quot; branch of the trees</li><li><code>depth</code>: The nodes&#39;s depth in the tree</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L114-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.Leaf" href="#BetaML.Trees.Leaf"><code>BetaML.Trees.Leaf</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Leaf(y,depth)</p><p>A tree&#39;s leaf (terminal) node.</p><p><strong>Constructor&#39;s arguments:</strong></p><ul><li><code>y</code>: The labels assorciated to each record (either numerical or categorical)</li><li><code>depth</code>: The nodes&#39;s depth in the tree</li></ul><p><strong>Struct members:</strong></p><ul><li><code>rawPredictions</code>: Either the label&#39;s count or the numerical labels of the members of the node</li><li><code>predictions</code>: Either the relative label&#39;s count (i.e. a PMF) or the mean</li><li><code>depth</code>: The nodes&#39;s depth in the tree</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L75-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.findBestSplit-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}} where Ty" href="#BetaML.Trees.findBestSplit-Union{Tuple{Ty}, Tuple{Any,Array{Ty,1}}} where Ty"><code>BetaML.Trees.findBestSplit</code></a> — <span class="docstring-category">Method</span></header><section><div><p>findBestSplit(x,y;maxFeatures,splittingCriterion)</p><p>Find the best possible split of the database.</p><p>Find the best question to ask by iterating over every feature / value and calculating the information gain.</p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: The feature dataset</li><li><code>y</code>: The labels dataset</li><li><code>maxFeatures</code>: Maximum number of (random) features to look up for the &quot;best split&quot;</li><li><code>splittingCriterion</code>: The metric to define the &quot;impurity&quot; of the labels</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L220-L233">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.infoGain-Tuple{Any,Any,Any}" href="#BetaML.Trees.infoGain-Tuple{Any,Any,Any}"><code>BetaML.Trees.infoGain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>infoGain(left, right, parentUncertainty; splittingCriterion)</p><p>Compute the information gain of a specific partition.</p><p>Compare the &quot;information gain&quot; my measuring the difference betwwen the &quot;impurity&quot; of the labels of the parent node with those of the two child nodes, weighted by the respective number of items.</p><p><strong>Parameters:</strong></p><ul><li><code>leftY</code>:  Child #1 labels</li><li><code>rightY</code>: Child #2 labels</li><li><code>parentUncertainty</code>: &quot;Impurity&quot; of the labels of the parent node</li><li><code>splittingCriterion</code>: Metric to adopt to determine the &quot;impurity&quot; (see below)</li></ul><p>You can use your own function as the metric. We provide the following built-in metrics:</p><ul><li><code>gini</code> (categorical)</li><li><code>entropy</code> (categorical)</li><li><code>variance</code> (numerical)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L195-L214">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.match-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx" href="#BetaML.Trees.match-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx"><code>BetaML.Trees.match</code></a> — <span class="docstring-category">Method</span></header><section><div><p>match(question, x)</p><p>Return a dicotomic answer of a question when applied to a given feature record.</p><p>It compares the feature value in the given record to the value stored in the question. Numerical features are compared in terms of disequality (&quot;&gt;=&quot;), while categorical features are compared in terms of equality (&quot;==&quot;).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L137-L146">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Trees.partition-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx" href="#BetaML.Trees.partition-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx},Any}} where Tx"><code>BetaML.Trees.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><p>partition(question,x)</p><p>Dicotomically partitions a dataset <code>x</code> given a question.</p><p>For each row in the dataset, check if it matches the question. If so, add it to &#39;true rows&#39;, otherwise, add it to &#39;false rows&#39;. Rows with missing values on the question column are assigned randomply proportionally to the assignment of the non-missing rows.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7fac8f383eb666890c021ddbefa56d3afc5d0dc6/src/Trees.jl#L157-L164">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Perceptron.html">« Perceptron</a><a class="docs-footer-nextpage" href="Nn.html">Nn »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 26 August 2020 10:36">Wednesday 26 August 2020</span>. Using Julia version 1.5.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
